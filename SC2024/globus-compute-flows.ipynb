{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40fa908",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Server-side Compute with Globus Compute + Flows\n",
    "<img src=\"images/globus-logo.png\" width=250 alt=\"Globus logo\" style=\"display:inline-block\">\n",
    "<img src=\"images/esgf.png\" width=250 alt=\"ESGF logo\" style=\"float:left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc6b02a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Use Case: Custom Computations\n",
    "What if we have a computation other than the typical averaging/subsetting/regridding workflows?\n",
    "\n",
    "An example: The El Niño Southern Oscillation (ENSO) Index:\n",
    "![ENSO Index](https://www.ncdc.noaa.gov/monitoring-content/teleconnections/nino-regions.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac741f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Solution: Globus Compute\n",
    "\n",
    "Thankfully, there is an existing solution to packaging custom computations, through a common API, allowing pre-defined functions to run in proximity to the datasets. From their documentation (https://www.globus.org/compute), their capabilities match our requirements:\n",
    "\n",
    "✅ …figuring out credentials and different authentication mechanisms\n",
    "\n",
    "✅ …configuring and managing batch jobs and schedulers\n",
    "\n",
    "✅ …interacting with resource managers, waiting in queues and scaling nodes\n",
    "\n",
    "✅ …configuring the execution environment for different compute systems\n",
    "\n",
    "✅ **…retrieving and sharing computation results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc6fb1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So I have a function I would like to share - where do I start?\n",
    "\n",
    "<img src=\"images/esgf-compute-diagram.png\" \n",
    "     width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55968e4e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 1. Write, register, and test your function\n",
    "As someone with access to the ESGF data holdings in a data center, you would:\n",
    "1. Write a function that locally accesses the data using `intake-esgf`\n",
    "2. Register the function with `globus-compute`\n",
    "3. Test the function on your local machine, using the unique ID of the function you registered to test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b830981",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 2. Share your function with the community.\n",
    "Now that you have a registered function, you can share that with a user group by:\n",
    "1. Creating a shared user group\n",
    "2. Adding that group as collaborators on your function using the web interface at globus.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492419c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Example of Calculating ENSO with Globus Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e3e1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imports and Pre-Requirements\n",
    "These imports and associated code would be run **within the data center, which has access to petabytes of earth system model output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa03529",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import hvplot.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from intake_esgf import ESGFCatalog\n",
    "import xarray as xr\n",
    "import cf_xarray\n",
    "import warnings\n",
    "import os\n",
    "from globus_compute_sdk import Executor, Client\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "hv.extension(\"bokeh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e8b09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Writing, Registering, and Testing our Function\n",
    "As mentioned in the introduction, we are utilizing functions from the previous ENSO notebooks. In order to run these with Globus Compute, we need to comply with the following requirements\n",
    "- All libraries/packages used in the function need to be installed on the globus compute endpoint\n",
    "- All functions/libraries/packages need to be imported and defined within the function to execute\n",
    "- The output from the function needs to serializable (ex. xarray.Dataset, numpy.array)\n",
    "\n",
    "Using these constraints, we setup the following function, with the key parameter being which modeling center (model) to compare. Two examples here include The National Center for Atmospheric Research (NCAR) and the Model for Interdisciplinary Research on Climate (MIROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb106c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_plot_enso(model, return_path=False):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from intake_esgf import ESGFCatalog\n",
    "    import xarray as xr\n",
    "    import cf_xarray\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def search_esgf(institution_id, grid='gn'):\n",
    "\n",
    "        # Search and load the ocean surface temperature (tos)\n",
    "        cat = ESGFCatalog()\n",
    "        cat.search(\n",
    "            activity_id=\"CMIP\",\n",
    "            experiment_id=\"historical\",\n",
    "            institution_id=institution_id,\n",
    "            variable_id=[\"tos\"],\n",
    "            member_id='r11i1p1f1',\n",
    "            table_id=\"Omon\",\n",
    "        )\n",
    "        try:\n",
    "            tos_ds = cat.to_datatree()[grid].to_dataset()\n",
    "        except ValueError:\n",
    "            tos_ds = cat.to_dataset_dict()[\"\"]\n",
    "\n",
    "        # Search and load the ocean grid cell area\n",
    "        cat = ESGFCatalog()\n",
    "        cat.search(\n",
    "            activity_id=\"CMIP\",\n",
    "            experiment_id=\"historical\",\n",
    "            institution_id=institution_id,\n",
    "            variable_id=[\"areacello\"],\n",
    "            member_id='r11i1p1f1',\n",
    "        )\n",
    "        try:\n",
    "            area_ds = cat.to_datatree()[grid].to_dataset()\n",
    "        except ValueError:\n",
    "            area_ds = cat.to_dataset_dict()[\"\"]\n",
    "        return xr.merge([tos_ds, area_ds])\n",
    "\n",
    "    def calculate_enso(ds):\n",
    "\n",
    "        # Subset the El Nino 3.4 index region\n",
    "        dso = ds.where(\n",
    "        (ds.cf[\"latitude\"] < 5) & (ds.cf[\"latitude\"] > -5) & (ds.cf[\"longitude\"] > 190) & (ds.cf[\"longitude\"] < 240), drop=True\n",
    "        )\n",
    "\n",
    "        # Calculate the monthly means\n",
    "        gb = dso.tos.groupby('time.month')\n",
    "\n",
    "        # Subtract the monthly averages, returning the anomalies\n",
    "        tos_nino34_anom = gb - gb.mean(dim='time')\n",
    "\n",
    "        # Determine the non-time dimensions and average using these\n",
    "        non_time_dims = set(tos_nino34_anom.dims)\n",
    "        non_time_dims.remove(ds.tos.cf[\"T\"].name)\n",
    "        weighted_average = tos_nino34_anom.weighted(ds[\"areacello\"]).mean(dim=list(non_time_dims))\n",
    "\n",
    "        # Calculate the rolling average\n",
    "        rolling_average = weighted_average.rolling(time=5, center=True).mean()\n",
    "        std_dev = weighted_average.std()\n",
    "        return rolling_average / std_dev\n",
    "\n",
    "    def add_enso_thresholds(da, threshold=0.4):\n",
    "\n",
    "        # Conver the xr.DataArray into an xr.Dataset\n",
    "        ds = da.to_dataset()\n",
    "\n",
    "        # Cleanup the time and use the thresholds\n",
    "        try:\n",
    "            ds[\"time\"]= ds.indexes[\"time\"].to_datetimeindex()\n",
    "        except:\n",
    "            pass\n",
    "        ds[\"tos_gt_04\"] = (\"time\", ds.tos.where(ds.tos >= threshold, threshold).data)\n",
    "        ds[\"tos_lt_04\"] = (\"time\", ds.tos.where(ds.tos <= -threshold, -threshold).data)\n",
    "\n",
    "        # Add fields for the thresholds\n",
    "        ds[\"el_nino_threshold\"] = (\"time\", np.zeros_like(ds.tos) + threshold)\n",
    "        ds[\"la_nina_threshold\"] = (\"time\", np.zeros_like(ds.tos) - threshold)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    ds = search_esgf(\"NCAR\")\n",
    "    enso_index = add_enso_thresholds(calculate_enso(ds).compute())\n",
    "    enso_index.attrs = ds.attrs\n",
    "    enso_index.attrs[\"model\"] = model\n",
    "\n",
    "    return enso_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558d662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4f9459e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Key Points\n",
    "\n",
    "- Great solution if a user needs custom computation next to the data\n",
    "- Minimizes data transfer by operating on the data where it is stored\n",
    "- `intake-esgf` is used to detect the file system, and access the data locally"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
